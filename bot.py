import tweepy
import os
import requests
import time
from xml.etree import ElementTree
import urllib.parse
from google import genai

# --- AI YAPILANDIRMASI ---
client_ai = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

def baglan():
    return tweepy.Client(
        consumer_key=os.environ.get("TWITTER_API_KEY"),
        consumer_secret=os.environ.get("TWITTER_API_SECRET"),
        access_token=os.environ.get("TWITTER_ACCESS_TOKEN"),
        access_token_secret=os.environ.get("TWITTER_ACCESS_TOKEN_SECRET")
    )

def analyze_and_write(haber_basligi, takim):
    """
    Haberi analiz eder ve TÃ¼rkÃ§e tweet yazar.
    404 hatasÄ±nÄ± Ã¶nlemek iÃ§in yedekli model sistemi kullanÄ±r.
    """
    prompt = f"""
    GÃ¶revin bir editÃ¶r ve filtreleyici olmak.
    Haber BaÅŸlÄ±ÄŸÄ± (Ä°ngilizce olabilir): "{haber_basligi}"
    Hedef TakÄ±m: {takim}

    AdÄ±mlar:
    1. Bu haberin ana konusu gerÃ§ekten {takim} veya {takim}'Ä±n bir oyuncusu/transferi mi?
    2. EÄŸer haber baÅŸka bir takÄ±m hakkÄ±ndaysa (ve {takim} sadece yan unsur ise) cevap olarak sadece "SKIP" yaz.
    3. EÄŸer haber {takim} hakkÄ±ndaysa: Bunu mÃ¼kemmel bir TÃ¼rkÃ§e ile, taraftarÄ± heyecanlandÄ±ran, emojili bir tweet metnine Ã§evir.
    4. KESÄ°NLÄ°KLE Ä°ngilizce kelime kullanma. Sadece TÃ¼rkÃ§e tweet metnini ver.
    """
    
    # Denenecek modeller listesi (Biri Ã§alÄ±ÅŸmazsa diÄŸerine geÃ§er)
    modeller = ["gemini-1.5-flash-002", "gemini-1.5-flash-001", "gemini-1.5-pro"]
    
    for model_ismi in modeller:
        try:
            response = client_ai.models.generate_content(
                model=model_ismi,
                contents=prompt
            )
            result = response.text.strip().replace('"', '')
            
            # BaÅŸarÄ±lÄ± cevap geldiyse dÃ¶ndÃ¼r
            if "SKIP" in result or len(result) < 5:
                return None
            return result
            
        except Exception as e:
            # Bu model hata verdiyse (404 vb.) dÃ¶ngÃ¼ bir sonraki modeli dener
            print(f"âš ï¸ Model ({model_ismi}) hatasÄ±, yedek modele geÃ§iliyor...")
            continue
            
    # HiÃ§bir model Ã§alÄ±ÅŸmazsa
    print("âŒ TÃ¼m AI modelleri hata verdi.")
    return None

def haber_tara():
    salter = os.environ.get("BOT_DURUMU", "ACIK").upper()
    if salter == "KAPALI": return

    try:
        limit = int(os.environ.get("HABER_SAYISI", "1"))
    except:
        limit = 1

    takimlar = ["FenerbahÃ§e", "Galatasaray", "BeÅŸiktaÅŸ", "Trabzonspor"]
    twitter_client = baglan()

    for takim in takimlar:
        print(f"ğŸŒ {takim} iÃ§in analiz baÅŸladÄ± ({limit} haber)...")
        
        # Arama sorgusu
        sorgu = urllib.parse.quote(f"{takim} transfer news")
        url = f"https://news.google.com/rss/search?q={sorgu}&hl=en-US&gl=US&ceid=US:en"
        
        paylasilan_sayisi = 0
        
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=10)
            root = ElementTree.fromstring(response.content)
            items = root.findall('./channel/item')

            for item in items:
                if paylasilan_sayisi >= limit:
                    break

                baslik = item.find('title').text
                link = item.find('link').text
                
                # AI Analizi
                tweet_metni = analyze_and_write(baslik, takim)
                
                if tweet_metni is None:
                    continue 

                tweet_final = f"{tweet_metni}\n\nğŸ”— Kaynak: {link}"
                twitter_client.create_tweet(text=tweet_final)
                
                print(f"âœ… {takim} haberi TÃ¼rkÃ§e paylaÅŸÄ±ldÄ±.")
                paylasilan_sayisi += 1
                time.sleep(15)
                
        except Exception as e:
            print(f"âš ï¸ {takim} aÄŸ hatasÄ±: {e}")

if __name__ == "__main__":
    haber_tara()
